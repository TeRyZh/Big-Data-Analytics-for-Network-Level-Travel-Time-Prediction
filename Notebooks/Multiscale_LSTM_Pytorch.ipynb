{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multiscale_LSTM_Pytorch.ipynb","provenance":[],"authorship_tag":"ABX9TyNi9mXjgMym8Lz2X1ZvzGUW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class UnfoldingLSTM(nn.ModuleList):\n","\tdef __init__(self, args):\n","\tsuper(UnfoldingLSTM, self).__init__()\n","\t\n","\t# Number of samples per time step\n","\tself.batch_size = 2\n","\t\n","\t# Dimension of weight vectors\n","\tself.hidden_dim = 16\n","\t\n","\t# Dimension of embedded tensor\n","\tself.embedding_dim = 2\n","\t\n","\t# The vocabulary size\n","\tself.input_size = 4\n","\t\n","\t# Number of time steps\n","\tself.sequence_len = 2\n","\t\n","\t# Initialize embedding layer\n","\tself.embedding = nn.Embedding(self.input_size, self.embedding_dim, padding_idx=0)\n","\t\n","\t# Initialize LSTM Cell\n","\tself.lstm_cell = nn.LSTMCell(self.embedding_dim, self.hidden_dim)"],"metadata":{"id":"66gsYCOfUROa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QUmsSfgUAwi"},"outputs":[],"source":["# Initialize LSTM Cell for the first layer\n","self.lstm_cell_layer_1 = nn.LSTMCell(self.embedding_dim, self.hidden_dim)\n","\n","# Initialize LSTM Cell for the second layer\n","self.lstm_cell_layer_2 = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n","\n","\n","# Initialize LSTM Cell for the second layer\n","self.lstm_cell_layer_2 = nn.LSTMCell(self.hidden_dim, self.hidden_dim)\n","\n","def forward(self, x):\n","\t\n","\t# batch_size x hidden_size\n","\thidden_state = torch.zeros(x.size(0), self.hidden_dim)\n","\tcell_state = torch.zeros(x.size(0), self.hidden_dim)\n","\thidden_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n","\tcell_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n"," \thidden_state_3 = torch.zeros(x.size(0), self.hidden_dim)\n","\tcell_state_3 = torch.zeros(x.size(0), self.hidden_dim)\n","\t\n","\t# weights initialization\n","\ttorch.nn.init.xavier_normal_(hidden_state)\n","\ttorch.nn.init.xavier_normal_(cell_state)\n","\ttorch.nn.init.xavier_normal_(hidden_state_2)\n","\ttorch.nn.init.xavier_normal_(cell_state_2)\n"," \ttorch.nn.init.xavier_normal_(hidden_state_3)\n","\ttorch.nn.init.xavier_normal_(cell_state_3)\n","\t\n","\t# From idx to embedding\n","\tout = self.embedding(x)\n","\t\n","\t# Prepare the shape for LSTMCell\n","\tout = out.view(self.sequence_len, x.size(0), -1)\n","\t\n","\t# Unfolding LSTM\n","\t# Last hidden_state will be used to feed the fully connected neural net\n","\tfor i in range(self.sequence_len):\n","\t\thidden_state, cell_state = self.lstm_cell_1(out[i], (hidden_state, cell_state))\n","\t  \n","    if i % step_1 == 0:\n","\n","\t\t    hidden_state_2, cell_state_2 = self.lstm_cell_2(hidden_state, (hidden_state_2, cell_state_2))\n","\t\t\t\n","\t\tif i % step_1 * step_2 == 0:\n","\t\t\t  \n","\t\t\t\thidden_state_3, cell_state_3 = self.lstm_cell_2(hidden_state, (hidden_state_3, cell_state_3))\n","\t\t\n","\t# Last hidden state is passed through a fully connected neural net\n","\tout = self.fully_connected(hidden_state_2)\t\n","\t\n","\treturn out"]},{"cell_type":"code","source":["import math\n","import numpy as np\n","\n","import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import pdb\n","\n","\"\"\"\n","Variable-length attention mechanism in hierarchical LSTM\n","\"\"\"\n","\n","class VLAttHierLstm(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, num_layers = 1):\n","        super(VLAttHierLstm, self).__init__()\n","\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # default maximum upgrade length\n","        self.up_len = 80\n","\n","        # bottom layer of LSTM\n","        self.bot_lstm = nn.LSTM(input_size, hidden_size, num_layers)             # lstm = rnn.LSTM(10, num_layers = 1, layout = 'NTC')\n","\n","        # top layer of LSTM\n","        self.top_lstm = nn.LSTM(hidden_size, hidden_size, num_layers)            # lstm = rnn.LSTM(10, num_layers = 1, layout = 'NTC')\n","\n","        # affine transformation for lstm hidden state\n","        self.att_hw = nn.Linear(hidden_size, hidden_size)                        # mx.symbol.FullyConnected\n","\n","        # affine transformation for context\n","        self.att_cw = nn.Linear(hidden_size, hidden_size)\n","\n","        # attention bias\n","        self.att_bias = nn.Parameter(torch.zeros(hidden_size))\n","\n","        # affine transformation for vector to scalar\n","        self.att_v2s = nn.Linear(hidden_size, 1)\n","\n","        # # initial states\n","        # self.h_0 = autograd.Variable(torch.zeros(1, 1, hidden_size)).cuda()\n","        # self.c_0 = autograd.Variable(torch.zeros(1, 1, hidden_size)).cuda()\n","\n","    def forward(self, x):\n","        bot_lstm_out, _ = self.bot_lstm(x)  # output, (hidden, cell) = lstm(input_data, begin_state)\n","\n","        output = None   # output of VLAttHierLstm\n","\n","        seq_len = len(x)\n","\n","        # set upgrade length\n","        up_len = min(self.up_len, math.floor(math.sqrt(seq_len)))\n","        # evenly spaced index\n","        idx = np.linspace(up_len - 1, math.pow(up_len, 2) - 1, num = up_len)\n","        # input for top lstm\n","        up_x = torch.cat([bot_lstm_out[i] for i in idx])\n","        # append the last output of bottom lstm\n","        if idx[-1] != seq_len - 1:\n","            up_x = torch.cat((up_x, bot_lstm_out[-1]))\n","\n","        # top_h_n is ctx (context)\n","        _, (ctx, _) = self.top_lstm(up_x.view(len(up_x), 1, -1))\n","\n","        for i in range(seq_len):\n","            y = bot_lstm_out[: (i + 1)]\n","            m = F.tanh(self.att_hw(y) + self.att_cw(ctx.expand(i + 1, -1, -1))\n","                       + self.att_bias.view(1, 1, -1).expand(i + 1, -1, -1))\n","            m = self.att_v2s(m)\n","            s = F.softmax(m, dim = 0)\n","            z = torch.sum(y * s, dim = 0).view(1, 1, -1)    # broadcasting when multiply y ans s\n","\n","            if output is None:\n","                output = z\n","            else:\n","                output = torch.cat((output, z), dim = 0)\n","\n","\n","\n","        return output"],"metadata":{"id":"M0icZDsE7riA"},"execution_count":null,"outputs":[]}]}